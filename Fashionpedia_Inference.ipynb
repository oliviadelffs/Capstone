{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Steps to run inference on [Fashionpedia](https://fashionpedia.github.io/home/index.html)'s attribute_mask_rcnn model and interpret results."
      ],
      "metadata": {
        "id": "lfJbvaYYUN1I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone [TensorFlow's TPU repository](https://github.com/tensorflow/tpu/blob/master/README.md), and make sure to have the right tensorflow version installed."
      ],
      "metadata": {
        "id": "u1SI039aVFNK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljFKl0GpUDU0"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/tensorflow/tpu/\n",
        "!pip uninstall tensorflow --y\n",
        "!pip install tensorflow==2.11"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To avoid moduleNotFound errors, add the following to your path:"
      ],
      "metadata": {
        "id": "BxIek_FMWENV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Clean and set PYTHONPATH\n",
        "os.environ['PYTHONPATH'] = (\n",
        "    \"~/tpu/models:\"\n",
        "    \"~/tpu/models/official/detection/dataloader:\"\n",
        "    \"~/tpu/models/official/efficientnet:\"\n",
        "    \"~/tpu/models/hyperparameters\"\n",
        ")"
      ],
      "metadata": {
        "id": "EtGvQCtEWLys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The file provided to run inference is found in the /tpu/models/official/detection/projects/fashionpedia folder. Make a copy and move it to the detection folder."
      ],
      "metadata": {
        "id": "Kdm8I-d5WjYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "source_path = '~/tpu/models/official/detection/projects/fashionpedia/inference.py'\n",
        "destination_path = '~/tpu/models/official/detection/inferencefp.py'\n",
        "\n",
        "try:\n",
        "    shutil.copy(source_path, destination_path)\n",
        "    print(f\"File copied successfully from {source_path} to {destination_path}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Source file not found at {source_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "id": "JnpJaBXwW5IW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To avoid error, line 170 in ~/tpu/models/detection/modeling/base_model.py must be changed."
      ],
      "metadata": {
        "id": "NZS-OFeeXW3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/tpu/models/official/detection/modeling/base_model.py'\n",
        "\n",
        "# Target line to replace and the replacement text\n",
        "target_line = 'self._skip_eval_loss = params.eval.skip_eval_loss'\n",
        "replacement_line = (\n",
        "    '    try:\\n'\n",
        "    '        self._skip_eval_loss = params.eval.skip_eval_loss\\n'\n",
        "    '    except KeyError as e:\\n'\n",
        "    '        self._skip_eval_loss = False\\n'\n",
        ")\n",
        "\n",
        "\n",
        "# Read and modify the file\n",
        "try:\n",
        "    with open(file_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    # Replace the target line\n",
        "    lines = [\n",
        "        replacement_line if line.strip() == target_line else line\n",
        "        for line in lines\n",
        "    ]\n",
        "\n",
        "    # Write the modified content back to the file\n",
        "    with open(file_path, 'w') as file:\n",
        "        file.writelines(lines)\n",
        "\n",
        "    print(\"File updated successfully!\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"File not found: {file_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "id": "enderPocXtI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are ready to run the model. First, download checkpoint file for desired backbone at: https://github.com/tensorflow/tpu/tree/master/models/official/detection/projects/fashionpedia. Next, change the path names to your path names in the code below and run."
      ],
      "metadata": {
        "id": "W76As2uzVbsW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python ~/tpu/models/official/detection/inferencefp.py \\\n",
        "  --model=\"attribute_mask_rcnn\" \\\n",
        "  --image_size=640 \\\n",
        "  # Update with path to checkpoint file\n",
        "  --checkpoint_path=\"/path/to/model.ckpt\" \\\n",
        "  # Update with name of yaml file\n",
        "  --config_file=\"~/tpu/models/official/detection/projects/fashionpedia/configs/yaml/backbone+ID_amrcnn.yaml\" \\\n",
        "  # If error with label map, download the file from the repository and change the path to your downloaded file\n",
        "  --label_map_file=\"~/tpu/models/official/detection/projects/fashionpedia/dataset/fashionpedia_label_map.csv\" \\\n",
        "  # Change jpg to the file type you are using\n",
        "  --image_file_pattern=\"/path/to/image/files/*.jpg\" \\\n",
        "  # Update with path to store results\n",
        "  --output_html=\"/path/to/your/output/folder/results.html\" \\\n",
        "  --output_file=\"/path/to/your/output/folder/results.npy\" \\\n",
        "  --max_boxes_to_draw=10 \\\n",
        "  --min_score_threshold=0.05"
      ],
      "metadata": {
        "id": "W92-tOvYYhuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To interpret category and annotation IDs, download and load the following:"
      ],
      "metadata": {
        "id": "vpqbDrVuakzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import json\n",
        "import requests\n",
        "\n",
        "url = \"https://s3.amazonaws.com/ifashionist-dataset/annotations/attributes_val2020.json\"\n",
        "\n",
        "response = requests.get(url)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    data_attributes = response.json()\n",
        "else:\n",
        "    print(f\"Failed to download the file, status code: {response.status_code}\")\n",
        "    data_attributes = {}\n",
        "\n",
        "url2 = \"https://s3.amazonaws.com/ifashionist-dataset/annotations/info_test2020.json\"\n",
        "\n",
        "response2 = requests.get(url2)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    data = response2.json()\n",
        "else:\n",
        "    print(f\"Failed to download the file, status code: {response.status_code}\")\n",
        "    data = {}"
      ],
      "metadata": {
        "id": "bRyyzKmtasSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, load your result npy file."
      ],
      "metadata": {
        "id": "C7QnSxdGcJhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = np.load('/path/to/your/output/folder/results.npy', allow_pickle=True)"
      ],
      "metadata": {
        "id": "RJLZDhFScNeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code with print your results.\n",
        "Example output:\n",
        "Image:  1\n",
        "Detected: bag, wallet with score 0.9994686841964722\n",
        "Bounding box: [870.7718  274.66696 977.52795 316.27097]\n",
        "Attributes: ID: 204, Name: set-in sleeve, ID: 160, Name: wrist-length, ID: 157, Name: short (length)"
      ],
      "metadata": {
        "id": "bjRUHsc5ceLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract categories\n",
        "categories = {category['id']: category for category in data['categories']}\n",
        "\n",
        "# Extract attributes\n",
        "attributes = data_attributes.get(\"attributes\", [])\n",
        "\n",
        "# Iterate through results and match category and attribute IDs to names\n",
        "count = 1\n",
        "for result in results:\n",
        "    print(\"Image: \", count)\n",
        "    count += 1\n",
        "    for cls, box, score, attribute_probs in zip(result[\"classes\"], result[\"boxes\"], result[\"scores\"], result[\"attributes\"]):\n",
        "        # Get the category name\n",
        "        category_name = categories.get(cls, {}).get('name', 'Unknown')\n",
        "\n",
        "        # Get the attributes sorted by probability\n",
        "        attribute_ids = np.argsort(attribute_probs)[::-1]  # Sort attributes by probability\n",
        "        attribute_info = []\n",
        "\n",
        "        for attr_id in attribute_ids:\n",
        "            # Get the attribute name using the attribute ID from data_attributes\n",
        "            if 0 <= attr_id < len(attributes):  # Ensure the attribute ID is valid\n",
        "                name = attributes[attr_id].get('name', 'Unknown')\n",
        "            else:\n",
        "                name = 'Unknown'\n",
        "\n",
        "            # If name is 'Unknown', still show the ID\n",
        "            if name == 'Unknown':\n",
        "                attribute_info.append(f\"ID: {attr_id}, Name: Unknown\")\n",
        "            else:\n",
        "                attribute_info.append(f\"ID: {attr_id}, Name: {name}\")\n",
        "\n",
        "        # Print the results with category and attribute names\n",
        "        print(f\"Detected: {category_name} with score {score}\")\n",
        "        print(f\"Bounding box: {box}\")\n",
        "        print(f\"Attributes: {', '.join(attribute_info) if attribute_info else 'No attributes detected'}\")\n"
      ],
      "metadata": {
        "id": "W7W0QNSVcxHb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}